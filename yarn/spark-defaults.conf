# Define qual gerenciador de recursos do cluster o Spark deve usar.
# 'yarn' significa que o Spark delegará ao YARN (do Hadoop) a responsabilidade de
# alocar/gerenciar containers (memória/CPU) para seus executores.
spark.master                     yarn

# Define onde o processo "Driver" (o "cérebro" da aplicação Spark) deve rodar.
# 'client' significa que o Driver rodará na máquina que executou o `spark-submit`
# (neste caso, o container 'master'), e não dentro de um container no cluster.
spark.submit.deployMode          client

# Define a quantidade de memória RAM alocada para o processo Driver (mencionado acima).
# '512m' = 512 megabytes.
spark.driver.memory              512m

# Define a quantidade de memória RAM padrão para cada "Executor".
# Executores são os processos "trabalhadores" (rodando nos NodeManagers/workers)
# que executam as tarefas (cálculos) da aplicação.
spark.executor.memory            512m

# 'AM' = ApplicationMaster. Quando uma aplicação Spark é submetida ao YARN,
# o YARN primeiro cria um container especial (o AM) para gerenciar aquela aplicação.
# Esta linha define a memória para esse container de gerenciamento (1 Gigabyte).
spark.yarn.am.memory             1G

# Configuração CRUCIAL para o History Server.
# 'true' habilita a gravação de logs de eventos estruturados do Spark.
# Estes logs registram tudo o que acontece na aplicação (jobs, stages, tarefas, etc.).
spark.eventLog.enabled           true

# Conectado com a linha acima. Define *onde* (em qual diretório) os logs de eventos
# devem ser escritos.
# Aqui, aponta para o diretório '/data-lake-logs' dentro do HDFS.
spark.eventLog.dir               hdfs://dsamaster:8080/data-lake-logs

# Esta é uma configuração do *lado do History Server*.
# Define qual "provedor" de backend o History Server usará para ler os logs.
# 'FsHistoryProvider' é o padrão, que lê de um sistema de arquivos (como HDFS ou local).
spark.history.provider           org.apache.spark.deploy.history.FsHistoryProvider

# Esta é a configuração MAIS IMPORTANTE do History Server.
# Ela diz ao 'FsHistoryProvider' (acima) *de onde* ele deve ler os logs.
# NOTE: Este caminho é o *mesmo* do 'spark.eventLog.dir'. É assim que
# o History Server encontra os logs que as aplicações escreveram.
spark.history.fs.logDirectory    hdfs://dsamaster:8080/data-lake-logs

# Informa ao YARN (especificamente ao ResourceManager) o endereço da UI do History Server.
# Isso permite que a UI do YARN crie links diretos